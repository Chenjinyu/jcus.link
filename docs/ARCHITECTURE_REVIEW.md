# Architecture Review & Recommendations

## Current Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€--â”
â”‚  Next.js (Vercel) â”‚
â”‚  - Chat Interface â”‚
â”‚  - API Routes     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€--â”
    â”‚           â”‚
    â–¼           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€-â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Supabaseâ”‚  â”‚ MCP Server        â”‚
â”‚ (Direct)â”‚  â”‚ (localhost:8080)  â”‚
â”‚         â”‚  â”‚                   â”‚
â”‚ Simple  â”‚  â”‚ Complex Ops       â”‚
â”‚ Queries â”‚  â”‚ - Resume Gen      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ - Job Analysis    â”‚
             â”‚                   â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ Supabaseâ”‚
                 â”‚ (Vector)â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Critical Issues

### 1. âŒ MCP Server Deployment
**Problem**: MCP server runs on `localhost:8080` - won't work in production on Vercel

**Solutions**:
- **Option A (Recommended)**: Deploy MCP server separately
  - Railway, Render, Fly.io, or AWS Lambda (with container)
  - Update `MCP_SERVER_URL` env var in Vercel
- **Option B**: Use Vercel Serverless Functions for Python
  - Convert MCP server to serverless functions
  - Higher latency, but simpler deployment
- **Option C**: Use Edge Functions
  - Deploy MCP logic as Vercel Edge Functions
  - Limited Python support, may need rewrite

### 2. âš ï¸ Direct Database Connection from Next.js
**Problem**: 
- Connection pooling issues with serverless functions
- Security: DB credentials in Next.js environment
- Cold starts create new connections each time

**Current Implementation** (`app/lib/embedding.ts`):
```typescript
// Direct Drizzle ORM connection
export const findRelevantContent = async (userQuery: string) => {
  const userQueryEmbedded = await generateEmbedding(userQuery);
  const similarGuides = await db
    .select({ name: embeddings.content, similarity })
    .from(embeddings)
    .where(gt(similarity, 0.5))
    .orderBy(t => desc(t.similarity))
    .limit(4);
  return simailarJointStr;
};
```

**Recommendations**:
- âœ… **Keep for simple queries** (low latency, acceptable for read-only)
- âš ï¸ **Add connection pooling** via Supabase connection pooler
- âš ï¸ **Use Supabase RPC functions** instead of direct queries when possible
- âœ… **Consider caching** for frequently accessed embeddings

### 3. ğŸ”„ Architecture Optimization

## Recommended Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Next.js (Vercel)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Chat Interface (Frontend)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                 â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  API Routes                   â”‚  â”‚
â”‚  â”‚  /api/chat                    â”‚  â”‚
â”‚  â”‚  /api/search                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€--â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”
    â”‚             â”‚ â”‚                     â”‚
    â”‚ Supabase    â”‚ â”‚  MCP Server         â”‚
    â”‚ (Direct)    â”‚ â”‚  (Deployed)         â”‚
    â”‚             â”‚ â”‚  - Railway/Render   â”‚
    â”‚ Simple      â”‚ â”‚  - Or Vercel Edge   â”‚
    â”‚ Queries     â”‚ â”‚                     â”‚
    â”‚             â”‚ â”‚  Complex Ops:       â”‚
    â”‚ - Similarityâ”‚ â”‚  - Resume Gen       â”‚
    â”‚ - Search    â”‚ â”‚  - Job Analysis     â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€--â”˜ â”‚  - File Processing  â”‚
          â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚
          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€--â”€â”˜
                 â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€-â”€â”
          â”‚  Supabase    â”‚
          â”‚  (Vector DB) â”‚
          â”‚  - pgvector  â”‚
          â”‚  - Embeddingsâ”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜
```

## Detailed Recommendations

### 1. MCP Server Deployment Strategy

#### Option A: Separate Deployment (Recommended)
```bash
# Deploy to Railway
railway up

# Or Render
# Create render.yaml with FastMCP service

# Environment Variables:
MCP_SERVER_URL=https://your-mcp-server.railway.app/mcp
```

**Pros**:
- âœ… Independent scaling
- âœ… Better for long-running operations
- âœ… Can use connection pooling
- âœ… Easier debugging

**Cons**:
- âš ï¸ Additional service to manage
- âš ï¸ Network latency between services

#### Option B: Vercel Serverless Functions
Convert MCP tools to individual serverless functions:
```
/api/mcp/upload-job-description
/api/mcp/search-resumes
/api/mcp/generate-resume
```

**Pros**:
- âœ… Same deployment as Next.js
- âœ… No separate service
- âœ… Automatic scaling

**Cons**:
- âš ï¸ Cold starts (Python functions slower)
- âš ï¸ 10s timeout limit (can extend to 60s)
- âš ï¸ More complex to maintain MCP protocol

### 2. Database Connection Optimization

#### Current: Direct Connection
```typescript
// app/lib/embedding.ts
import { db } from '../../db'; // Drizzle ORM
```

#### Recommended: Use Supabase RPC Functions
```typescript
// Create SQL function in Supabase
CREATE OR REPLACE FUNCTION search_similar_content(
  query_embedding vector(1536),
  similarity_threshold float DEFAULT 0.5,
  result_limit int DEFAULT 4
)
RETURNS TABLE (
  content text,
  similarity float
) AS $$
BEGIN
  RETURN QUERY
  SELECT 
    e.content,
    1 - (e.embedding <=> query_embedding) as similarity
  FROM embeddings e
  WHERE 1 - (e.embedding <=> query_embedding) > similarity_threshold
  ORDER BY similarity DESC
  LIMIT result_limit;
END;
$$ LANGUAGE plpgsql;

// Then in Next.js
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);

export const findRelevantContent = async (userQuery: string) => {
  const embedding = await generateEmbedding(userQuery);
  
  const { data, error } = await supabase.rpc('search_similar_content', {
    query_embedding: embedding,
    similarity_threshold: 0.5,
    result_limit: 4
  });
  
  return data?.map(d => d.content).join('\n') || '';
};
```

**Benefits**:
- âœ… Connection pooling via Supabase
- âœ… Better performance (server-side execution)
- âœ… Reduced cold start impact
- âœ… More secure (no direct DB access)

### 3. Caching Strategy

Add caching for frequently accessed embeddings:

```typescript
// app/lib/cache.ts
import { Redis } from '@upstash/redis'; // Vercel-compatible Redis

const redis = new Redis({
  url: process.env.UPSTASH_REDIS_URL!,
  token: process.env.UPSTASH_REDIS_TOKEN!,
});

export const getCachedEmbedding = async (text: string) => {
  const key = `embedding:${hash(text)}`;
  const cached = await redis.get(key);
  if (cached) return cached;
  
  const embedding = await generateEmbedding(text);
  await redis.set(key, embedding, { ex: 3600 }); // 1 hour TTL
  return embedding;
};
```

### 4. Request Flow Optimization

#### Simple Queries (Current - Keep)
```
User Query â†’ Next.js API â†’ Direct Supabase â†’ Response
Latency: ~100-200ms
```

#### Complex Operations (Current - Improve)
```
User Query â†’ Next.js API â†’ MCP Server â†’ Supabase â†’ LLM â†’ Response
Latency: ~2-5s
```

**Optimization**: Pre-process job descriptions
```
Upload Job â†’ MCP Server â†’ Store in DB â†’ Return Job ID
Query Match â†’ Next.js â†’ Direct Supabase (use stored job embedding)
Generate Resume â†’ MCP Server â†’ Use cached matches
```

### 5. Error Handling & Resilience

Add retry logic and fallbacks:

```typescript
// app/utils/mcp-client-sdk.ts
import { retry } from 'ts-retry';

export async function generateResume(...) {
  return await retry(
    async () => {
      const client = await getMCPClient();
      return await client.callTool('generate_resume', {...});
    },
    {
      retries: 3,
      delay: 1000,
      backoff: 'EXPONENTIAL',
      onRetry: (error, attempt) => {
        console.log(`Retry attempt ${attempt} for generateResume`);
      }
    }
  );
}
```

### 6. Monitoring & Observability

Add logging and metrics:

```typescript
// app/api/chat/route.ts
import { log } from '@vercel/analytics';

export async function POST(req: Request) {
  const startTime = Date.now();
  
  try {
    // ... existing code ...
    
    log('chat_request', {
      model: selectedModel,
      hasAttachments: attachments.length > 0,
      mcpToolsUsed: mcpToolSelection.tools,
    });
    
    return response;
  } finally {
    const duration = Date.now() - startTime;
    console.log(`[METRICS] Chat request took ${duration}ms`);
  }
}
```

## Implementation Priority

### Phase 1: Critical (Do First)
1. âœ… Deploy MCP server to production (Railway/Render)
2. âœ… Update `MCP_SERVER_URL` environment variable
3. âœ… Add connection pooling for Supabase (use connection string with pooler)
4. âœ… Add error handling and retries

### Phase 2: Optimization (Do Next)
1. âš ï¸ Migrate simple queries to Supabase RPC functions
2. âš ï¸ Add caching for embeddings
3. âš ï¸ Implement request queuing for MCP operations
4. âš ï¸ Add monitoring and analytics

### Phase 3: Enhancement (Nice to Have)
1. ğŸ’¡ Add WebSocket support for real-time resume generation
2. ğŸ’¡ Implement streaming responses for long operations
3. ğŸ’¡ Add rate limiting per user
4. ğŸ’¡ Cache generated resumes

## Environment Variables Checklist

```env
# Next.js (Vercel)
DATABASE_URL=postgresql://... (with connection pooler)
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_KEY=xxx
MCP_SERVER_URL=https://your-mcp-server.railway.app/mcp

# MCP Server (Railway/Render)
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_KEY=xxx
LLM_API_KEY=xxx
HOST=0.0.0.0
PORT=8000
```

## Testing Strategy

1. **Local Development**:
   - MCP server: `localhost:8080`
   - Next.js: `localhost:3000`
   - Test full flow end-to-end

2. **Staging**:
   - Deploy MCP server to staging
   - Deploy Next.js to Vercel preview
   - Test with production-like data

3. **Production**:
   - Monitor latency and errors
   - Set up alerts for MCP server downtime
   - Track usage metrics

## Summary

Your architecture is **solid** with good separation of concerns. Main improvements needed:

1. **Deploy MCP server** to production (not localhost)
2. **Optimize database connections** (use Supabase RPC + connection pooler)
3. **Add caching** for frequently accessed data
4. **Improve error handling** with retries and fallbacks

The direct DB connection for simple queries is **acceptable** but can be optimized further with RPC functions and caching.

